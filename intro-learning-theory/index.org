#+TITLE: Introduction to Statistical Learning Theory

* What is Learning?

Or what is Machine Learning? Let's attempt a formalization.

: show hypothesis classes

* What is a Theory?
#+begin_quote
Theory explains observations
#+end_quote

* Why learn Theory?
** Exhibit #1
First Class Functions

: show decorator example

** Exhibit #2
*nix pipes

: show DDIA map-reduce example

** Exhibit #3
Cooley-Tukey Algorithm

: show FFT

** Exhibit #4
Weak learners and AdaBoost. We will come back to this in a while.

* Why learn Theory?
#+begin_quote
Theory tells you the core constructs and their interactions. That helps to
create novel interventions.

Theory unlocks hackability for a domain.
#+end_quote

- Shell Theory is for automation hackers
- Computational Complexity Theory is for algorithm hackers
- ML Theory is for ML hackers
- *Theory is for hackers*

* What is Learning Theory?
Learning setting.

: go back to first example, cover ERM.

** Concepts
- Problem
- Sample
- Hypotheses Class
  - Realizable and agnostic
  - Capacity
- Risk
  - Empirical and Generalization
  - Decomposition
- Training Algorithm

** PAC Learning, VC-dimension, etcetera
: page 44, UML

$R(h)\leq R_{emp}(h)+C(|\mathscr{H}|,N, \delta)$

** Generalization Gap
True learning problem.

: remark on random learning

* AdaBoost
How will you invent boosting?

* AdaBoost
- Origin. Weak Learners.
- How to reason out overfitting? Resort to bounds.

- Boosting problem
- Training error from paper
- Generalization bound from UML and paper

* Resources
Links used during the session:
+ [[file:./scratch.pdf][Poorly written notes]]
+ [[https://en.wikipedia.org/wiki/Cooley%E2%80%93Tukey_FFT_algorithm#History][Cooleyâ€“Tukey FFT algorithm - Wikipedia]]
+ [[https://en.wikipedia.org/wiki/AdaBoost][AdaBoost - Wikipedia]]

More resources to read:
+ [[https://www.amazon.in/Understanding-Machine-Learning-Theory-Algorithms-ebook/dp/B00J8LQU8I][Understanding Machine Learning: From Theory to Algorithms eBook : Shalev-Shwa...]]
+ [[https://cseweb.ucsd.edu/~yfreund/papers/IntroToBoosting.pdf][A Short Introduction to Boosting]]
+ [[https://proceedings.neurips.cc/paper/2007/file/0d3180d672e08b4c5312dcdafdf6ef36-Paper.pdf][The Tradeoffs of Large Scale Learning]]+
 [[https://cacm.acm.org/magazines/2021/3/250713-understanding-deep-learning-still-requires-rethinking-generalization/fulltext][Understanding Deep Learning (Still) Requires Rethinking Generalization | Marc...]]
